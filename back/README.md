# RAG API Микросервис

## 1. Краткое описание

RAG API — это микросервис, реализующий систему Retrieval-Augmented Generation (RAG). Он предназначен для ответов на вопросы пользователей на основе информации, хранящейся в базе знаний. Сервис обрабатывает загружаемые документы (TXT, PDF, DOCX), индексирует их содержимое и использует для генерации ответов с помощью больших языковых моделей (LLM).

Ключевые функции сервиса:
1.  **Обработка вопросов пользователей (RAG пайплайн)**:
    *   Прием вопроса от пользователя.
    *   Классификация вопроса (например, "Lookup", "Calculation").
    *   Обогащение запроса с помощью LLM для улучшения качества поиска.
    *   Поиск релевантных фрагментов в базе знаний (Qdrant) с использованием векторных представлений и динамически генерируемых фильтров.
    *   Переранжирование найденных фрагментов для повышения точности.
    *   Формирование промпта для LLM, включающего историю диалога (если применимо) и наиболее релевантный контекст из базы знаний.
    *   Генерация ответа с помощью LLM (поддерживаются OpenAI-совместимые локальные LLM и Google Gemini API).
    *   Сбор и сохранение метрик RAG-процесса (релевантность, использованные фрагменты, время генерации и т.д.).
2.  **Управление базой знаний**:
    *   Загрузка документов в форматах TXT, PDF, DOCX.
    *   Автоматическое извлечение текста (и таблиц из DOCX в формате Markdown).
    *   Разделение извлеченного контента на управляемые фрагменты (чанки).
    *   Генерация векторных представлений (embeddings) для каждого чанка.
    *   Сохранение чанков и их векторов в Qdrant, а метаданных документов — в MongoDB.
    *   Получение списка загруженных документов с основной информацией.
    *   Удаление документов и связанных с ними данных из базы знаний.
3.  **Управление историей диалогов**:
    *   Сохранение истории сообщений (пользовательских запросов и ответов ассистента) в MongoDB.
    *   Возможность очистки истории сообщений для конкретного пользователя.
    *   Просмотр истории всех чатов с детальными метриками RAG через встроенный HTML-интерфейс.
4.  **Вспомогательные LLM-функции**:
    *   Классификация типов вопросов пользователей.
    *   Обогащение и переформулирование пользовательских запросов для оптимизации поиска.
    *   Суммаризация истории диалогов для использования в сложных сценариях поиска.
    *   Генерация ключевых слов и фильтров для Qdrant на основе содержания вопроса.

## 2. Архитектура и технологии

Микросервис построен с использованием Python и FastAPI, реализуя асинхронный RAG-пайплайн.

*   **Язык программирования**: Python 3.9+
    *   *Обоснование*: Обширная экосистема библиотек для NLP и машинного обучения, зрелая поддержка асинхронности, высокая продуктивность разработки.
*   **Веб-фреймворк**: FastAPI
    *   *Обоснование*: Высокая производительность, встроенная поддержка асинхронности, автоматическая генерация интерактивной документации API (Swagger UI, ReDoc) на основе типизации Pydantic, простота разработки.
*   **База данных (метаданные документов, история чатов, метрики)**: MongoDB
    *   *Обоснование*: Гибкая схема данных (document-oriented), хорошо подходящая для хранения структурированной и полуструктурированной информации (метаданные файлов, логи сообщений, RAG-метрики).
*   **Векторная база данных**: Qdrant
    *   *Обоснование*: Специализированная высокопроизводительная база данных для хранения и поиска векторных представлений. Поддерживает фильтрацию метаданных, различные метрики расстояния и оптимизирована для задач семантического поиска, ключевых для RAG.
*   **Модели для генерации векторных представлений (Embeddings)**: SentenceTransformers (например, `ai-forever/sbert_large_nlu_ru`)
    *   *Обоснование*: Качественные предобученные модели для русского языка, обеспечивающие хорошие результаты в задачах семантического сходства. Легко интегрируются и используются.
*   **Модель для переранжирования (Reranker)**: CrossEncoder (например, `cross-encoder/ms-marco-MiniLM-L-6-v2`)
    *   *Обоснование*: Позволяет повысить точность отбора релевантных фрагментов после первоначального векторного поиска, оценивая пары "запрос-документ" более детально.
*   **Большие языковые модели (LLM)**:
    *   Локальные LLM через OpenAI-совместимый API (например, инференс-серверы типа vLLM, Ollama, TGI).
    *   Google Gemini API.
    *   *Обоснование*: Гибкость в выборе LLM, возможность использования как полностью контролируемых локальных моделей, так и мощных облачных API.
*   **Обработка документов**:
    *   `PyPDF2` для извлечения текста из PDF-файлов.
    *   `python-docx` для извлечения текста и таблиц (в формате Markdown) из DOCX-файлов.
    *   *Обоснование*: Стандартные и проверенные библиотеки для работы с указанными форматами.
*   **HTTP-клиент**: `httpx`
    *   *Обоснование*: Современный асинхронный HTTP-клиент, совместимый с асинхронной природой FastAPI.
*   **Управление конфигурацией**: Файл `.env` с использованием библиотеки `python-dotenv`.
    *   *Обоснование*: Стандартный и удобный способ управления конфигурационными параметрами приложения.
*   **ASGI-сервер**: Uvicorn
    *   *Обоснование*: Рекомендуемый ASGI-сервер для запуска FastAPI приложений.
*   **API протокол**: REST.
*   **Аутентификация API**: Не реализована (эндпоинты сервиса открыты). Аутентификация для доступа к внешним сервисам (LLM, Qdrant) настраивается через переменные окружения.



## 3. Настройка окружения
Создайте файл `.env` в корневой директории проекта. Вы можете скопировать `backend_rag.py` переменные окружения по-умолчанию или использовать следующий пример, адаптировав значения под вашу конфигурацию:

```env
# MongoDB Configuration
MONGO_URI=mongodb://root:example@localhost:27017

# Qdrant Configuration
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION_NAME=horoshaya_svyaz_kb_telegram_v1 # Или другое имя коллекции
# QDRANT_API_KEY= # Укажите, если ваш Qdrant требует API ключ

# Embedding and Reranker Models (из Hugging Face)
EMBEDDING_MODEL_NAME=ai-forever/sbert_large_nlu_ru
RERANKER_MODEL_NAME=cross-encoder/ms-marco-MiniLM-L-6-v2

# LLM Configuration (OpenAI-совместимый API для локальных моделей)
OPENAI_API_BASE=http://localhost:8001/v1 # URL вашего локального LLM-сервера
OPENAI_API_KEY=DUMMY_KEY                # API ключ (может быть любым, если LLM не требует)
OPENAI_MODEL_NAME=local-model-name      # Название модели, обслуживаемой вашим LLM

# Gemini API Configuration (Опционально)
GEMINI_API_KEY=YOUR_GEMINI_API_KEY     # Ваш API ключ для Google Gemini
GEMINI_MODEL_NAME=gemini-1.5-flash     # Модель Gemini

# RAG Pipeline Configuration
TOTAL_CONTEXT_WINDOW_TOKENS=16000      # Общий размер контекстного окна LLM
RESPONSE_BUFFER_TOKENS=4096            # Резерв токенов для генерации ответа
# BASE_PROMPT_TOKENS=800               # Задается в коде, но влияет на доступные токены
MAX_HISTORY_MESSAGES_TO_FETCH=15       # Макс. сообщений истории для контекста
MAX_QDRANT_RESULTS_TO_FETCH=20         # Макс. фрагментов из Qdrant для рассмотрения
QDRANT_SCORE_THRESHOLD=0.6             # Начальный порог релевантности для Qdrant
MIN_RERANK_SCORE=0.8                   # Минимальный порог после переранжирования

# File Uploads
UPLOAD_FOLDER=uploads_telegram         # Временная папка для загружаемых файлов
```

### Запуск зависимых сервисов (MongoDB, Qdrant)
Рекомендуется использовать Docker Compose. Создайте файл `docker-compose.yml` в корне проекта:
```yaml
version: '3.8'

services:
  mongo:
    image: mongo:latest
    container_name: rag_mongo
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: root    # Должно совпадать с .env, если используется
      MONGO_INITDB_ROOT_PASSWORD: example # Должно совпадать с .env, если используется
    volumes:
      - mongo_data:/data/db
    restart: unless-stopped

  qdrant:
    image: qdrant/qdrant:latest
    container_name: rag_qdrant
    ports:
      - "6333:6333" # HTTP API
      - "6334:6334" # gRPC API
    volumes:
      - qdrant_storage:/qdrant/storage
    # Для production рекомендуется использовать файл конфигурации Qdrant
    # configs/qdrant_config.yaml и монтировать его:
    # - ./configs/qdrant_config.yaml:/qdrant/config/production.yaml
    restart: unless-stopped

volumes:
  mongo_data:
  qdrant_storage:
```


###  Доступ к API и документации
После успешного запуска сервис будет доступен по адресу `http://localhost:8000`.
*   Интерактивная документация API (Swagger UI): `http://localhost:8000/docs`
*   Альтернативная документация (ReDoc): `http://localhost:8000/redoc`

## 4. Примеры использования API

Ниже приведены примеры взаимодействия с основными эндпоинтами API.

### 4.1. Задать вопрос системе
**Эндпоинт**: `POST /ask`

Отправляет вопрос пользователя в RAG-систему.

**Пример запроса (curl):**
```bash
curl -X POST "http://localhost:8000/ask" \
-H "Content-Type: application/json" \
-d '{
  "user_id": 101,
  "question": "Расскажи про условия премирования за продажу пакета 'Эксклюзив'"
}'
```

**Пример ответа (JSON):**
```json
{
  "answer": "За продажу пакета 'Эксклюзив' предусмотрена премия в размере 5000 рублей при выполнении плана продаж на 100% и дополнительный бонус 5% от стоимости пакета, если клиент также подключил услугу 'VIP-поддержка'.",
  "metrics": {
    "rag_metrics": {
      "relevance_scores": [0.95, 0.89],
      "context_tokens": 620,
      "used_chunks": 2,
      "generation_time": 7.123,
      "answer_tokens": 78,
      "average_relevance_score": 0.92,
      "context_chunks": [
        "Фрагмент 1 из 'Положение о премировании.docx': ...условия для пакета Эксклюзив...",
        "Фрагмент 2 из 'Тарифы и услуги.pdf': ...VIP-поддержка и её связь с Эксклюзив..."
      ],
      "qdrant_filters": ["премирование", "эксклюзив", "продажа", "бонус"]
    },
    "user_id": 101,
    "classified_category": "Lookup",
    "prompt_source": "Qdrant Only",
    "fallback_rag_attempted": false,
    "qdrant_initial_hits_found": 5,
    "qdrant_fallback_hits_found": 0,
    "qdrant_error": false,
    "is_first_assistant_message": false
  }
}
```

### 4.2. Загрузить документ в базу знаний
**Эндпоинт**: `POST /upload`

Загружает новый документ (TXT, PDF, DOCX) для индексации.

**Пример запроса (curl для загрузки файла):**
```bash
curl -X POST "http://localhost:8000/upload" \
-F "file=@/путь/к/локальному/файлу/инструкция_по_безопасности.pdf"
```

**Пример успешного ответа (JSON):**
```json
{
  "success": true,
  "message": "a1b2c3d4-e5f6-7890-1234-567890abcdef" // ID документа в MongoDB
}
```
**Пример ответа при ошибке (JSON):**
```json
{
  "detail": "File type not allowed: инструкция.zip" // Статус 400
}
```

### 4.3. Получить список документов в базе знаний
**Эндпоинт**: `GET /documents`

Возвращает список всех активных документов.

**Пример запроса (curl):**
```bash
curl -X GET "http://localhost:8000/documents"
```

**Пример ответа (JSON):**
```json
{
  "documents": [
    {
      "_id": "a1b2c3d4-e5f6-7890-1234-567890abcdef",
      "filename": "инструкция_по_безопасности.pdf",
      "upload_time": "2024-07-15T10:00:00.000Z", // ISO 8601 формат
      "chunk_count": 25,
      "upload_time_str": "2024-07-15 10:00:00 UTC"
    },
    {
      "_id": "b2c3d4e5-f6a7-8901-2345-678901bcdef0",
      "filename": "Положение о премировании.docx",
      "upload_time": "2024-07-14T15:30:00.000Z",
      "chunk_count": 18,
      "upload_time_str": "2024-07-14 15:30:00 UTC"
    }
  ]
}
```

### 4.4. Удалить документ из базы знаний
**Эндпоинт**: `DELETE /documents/{doc_id}`

Удаляет документ и все связанные с ним данные (из MongoDB и Qdrant) по ID документа.

**Пример запроса (curl):**
```bash
curl -X DELETE "http://localhost:8000/documents/a1b2c3d4-e5f6-7890-1234-567890abcdef"
```

**Пример успешного ответа (JSON):**
```json
{
  "success": true,
  "message": "Document 'инструкция_по_безопасности.pdf' and its associated data deleted successfully."
}
```

### 4.5. Очистить историю чата пользователя
**Эндпоинт**: `DELETE /history/{user_id}`

Удаляет все сообщения для указанного `user_id`.

**Пример запроса (curl):**
```bash
curl -X DELETE "http://localhost:8000/history/101"
```

**Пример успешного ответа (JSON):**
```json
{
  "success": true,
  "message": "История сообщений (42 сообщений) была очищена."
}
```

### 4.6. Просмотреть историю всех чатов
**Эндпоинт**: `GET /history`

Открывает HTML-страницу в браузере, отображающую историю всех диалогов с пользователями, включая сообщения и RAG-метрики для ответов ассистента.

**Пример использования:**
Просто откройте `http://localhost:8000/history` в вашем веб-браузере.